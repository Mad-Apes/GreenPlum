## 准备4台机器[CentOS7]
```
    192.168.138.136 GP_Master
    192.168.138.137 GP_Segment_1
    192.168.138.138 GP_Segment_2
    192.168.138.139 GP_Segment_3
  配置如下
    IP                 host_name        内  存       硬  盘
    192.168.138.136    GP_Master          4G          70G
    192.168.138.137    GP_Segment_1       4G          70G
    192.168.138.138    GP_Segment_2       4G          70G
    192.168.138.139    GP_Segment_3       4G          70G
```
## 设置主机名
```
    [root@localhost /]# vim /etc/hosts
    添加以下内容：
    192.168.138.136 GP_Master
    192.168.138.137 GP_Segment_1
    192.168.138.138 GP_Segment_2
    192.168.138.139 GP_Segment_3
```
## 修改各个节点/etc/sysconfig/network文件
```
[root@ gp-master ~]# vi /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=GP_Master
```
## 修改系统内核配置（所有机器）
```
vim /etc/sysctl.conf
添加以下内容：
kernel.shmmax = 500000000
kernel.shmmni = 4096
kernel.shmall = 4000000000
kernel.sem = 250 512000 100 2048
kernel.sysrq = 1
kernel.core_uses_pid = 1
kernel.msgmnb = 65536
kernel.msgmax = 65536
kernel.msgmni = 2048
net.ipv4.tcp_syncookies = 1
net.ipv4.ip_forward = 0
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_max_syn_backlog = 4096
net.ipv4.conf.all.arp_filter = 1
net.ipv4.ip_local_port_range = 1025 65535
net.core.netdev_max_backlog = 10000
net.core.rmem_max = 2097152
net.core.wmem_max = 2097152
vm.overcommit_memory = 2

执行 sysctl -p 生效
```
## 修改进程数/etc/security/limits.d/90-nproc.conf文件
```
vim /etc/security/limits.d/90-nproc.conf
*          soft    nproc     131072
root       soft    nproc     unlimited
```

## 修改文件打开限制
```
vim /etc/security/limits.conf

* soft nofile 65536

* hard nofile 65536

* soft nproc 131072

* hard nproc 131072
```

## 关闭SELINUX安全设置
```
vim /etc/selinux/config

# This file controls the state of SELinux on the system.

# SELINUX= can take one of these three values:

# enforcing - SELinux security policy is enforced.

# permissive - SELinux prints warnings instead of enforcing.

# disabled - No SELinux policy is loaded.

SELINUX=disabled

# SELINUXTYPE= can take one of these two values:

# targeted - Targeted processes are protected,

# mls - Multi Level Security protection.

SELINUXTYPE=targeted
```

## 关闭防火墙（所有机器）
```
systemctl start firewalld.service#启动firewall
systemctl stop firewalld.service#停止firewall
systemctl disable firewalld.service#禁止firewall开机启动

service iptables stop
chkconfig iptables off
```
## 创建用户和组（所有机器）
```
groupadd -g 530 gpadmin
useradd -g 530 -u 530 -m -d /home/gpadmin -s /bin/bash gpadmin
passwd gpadmin
chown -R gpadmin:gpadmin /home/gpadmin
echo "gpadmin" | passwd --stdin gpadmin
```
#安装和分发[rpm 方式]
##联网安装必要的包 (所有机器)
```
GP_Master 机器上：
将安装包[greenplum-db-5.16.0-rhel7-x86_64.rpm]上传到 /home/gpadmin

安装命令
rpm -ivh greenplum-db-5.0.0-rhel6-x86_64.rpm

默认的安装路径是/usr/local，然后需要修改该路径gpadmin操作权限：
chown -R gpadmin:gpadmin /usr/local

创建一个hostlist,包含所有节点主机名：
su - gpadmin
mkdir -p /home/gpadmin/conf
vim /home/gpadmin/conf/hostlist
GP_Master
GP_Segment_1
GP_Segment_2
GP_Segment_3

创建一个 seg_hosts ，包含所有的Segment Host的主机名：
vim /home/gpadmin/conf/seg_hosts

GP_Segment_1
GP_Segment_2
GP_Segment_3


 配置ssh免密连接
 [root@ gp-master ~]# su - gpadmin
[gpadmin@ gp-master ~]# source /usr/local/greenplum-db/greenplum_path.sh  
[gpadmin@ gp-master ~]# gpssh-exkeys -f /home/gpadmin/conf/hostlist
[STEP 1 of 5] create local ID and authorize on local host

[STEP 2 of 5] keyscan all hosts and update known_hosts file

[STEP 3 of 5] authorize current user on remote hosts
  ... send to GP_Master
  ... send to GP_Segment_1
  ***
  *** Enter password for GP_Segment_1:
  ... send to GP_Segment_2
  ... send to GP_Segment_3

[STEP 4 of 5] determine common authentication file content

[STEP 5 of 5] copy authentication files to all remote hosts
  ... finished key exchange with GP_Master
  ... finished key exchange with GP_Segment_1
  ... finished key exchange with GP_Segment_2
  ... finished key exchange with GP_Segment_3

[INFO] completed successfully


测试免密连接是否成功：
[gpadmin@GP_Master ~]$ gpssh -f /home/gpadmin/conf/hostlist
=> pwd
[GP_Segment_2] /home/gpadmin
[GP_Segment_3] /home/gpadmin
[   GP_Master] /home/gpadmin
[GP_Segment_1] /home/gpadmin
=> exit


在Segment节点上安装Greenplum DB
在各个子节点进行文件夹赋权：

chown -R gpadmin:gpadmin /usr/local
chown -R gpadmin:gpadmin /opt
在主节点打包安装包并复制到各个子节点：

[gpadmin@mdw conf]$ cd /usr/local/
打包：
[gpadmin@mdw greenplum]$ tar -cf gp.tar greenplum-db-5.16.0/
[gpadmin@mdw conf]$ source /usr/local/greenplum-db/greenplum_path.sh
[gpadmin@mdw greenplum]$ gpscp -f /home/gpadmin/conf/seg_hosts gp.tar =:/usr/local/
ok，如果没有意外，就批量复制成功了，可以去子节点的相应文件夹查看，之后要将tar包解压，现在我们将采用对子节点使用批量解压操作：

[gpadmin@mdw conf]$ gpssh -f /home/gpadmin/conf/seg_hosts  #统一处理子节点

=> cd /usr/local
[GP_Segment_3]
[GP_Segment_1]
[GP_Segment_2]
=> tar -xf gp.tar
[GP_Segment_3]
[GP_Segment_1]
[GP_Segment_2]

#建立软链接
=> ln -s ./greenplum-db-5.16.0 greenplum-db
[GP_Segment_3]
[GP_Segment_1]
[GP_Segment_2]
=> ll(可以使用ll查看一下是否已经安装成功)
=>exit(退出)
这样就完成了所有节点的安装。

创建资源目录
source /usr/local/ greenplum-db/greenplum_path.sh
gpssh -f /home/gpadmin/conf/hostlist #统一处理所有节点

#创建资源目录 /opt/greenplum/data下一系列目录（生产目录个数可根据需求生成）
=> mkdir -p /opt/greenplum/data/master
=> mkdir -p /opt/greenplum/data/primary
=> mkdir -p /opt/greenplum/data/mirror
=> mkdir -p /opt/greenplum/data2/primary
=> mkdir -p /opt/greenplum/data2/mirror

在主节点进行环境变量配置
vi /home/gpadmin/.bash_profile 在最后添加

source /usr/local/greenplum-db/greenplum_path.sh
export MASTER_DATA_DIRECTORY=/opt/greenplum/data/master/gpseg-1
export GPPORT=5432
export PGDATABASE=MAD_APES

然后依次复制到各个子节点:
scp /home/gpadmin/.bash_profile GP_Segment_1:/home/gpadmin/
scp /home/gpadmin/.bash_profile GP_Segment_2:/home/gpadmin/
scp /home/gpadmin/.bash_profile GP_Segment_3:/home/gpadmin/
让环境变量生效:
source /home/gpadmin/.bash_profile

NTP 配置
启用master节点上的ntp，并在Segment节点上配置和启用NTP：
echo "server GP_Master perfer" >>/etc/ntp.conf
gpssh -f /home/gpadmin/conf/hostlist -v -e 'sudo ntpd'
gpssh -f /home/gpadmin/conf/hostlist -v -e 'sudo /etc/init.d/ntpd start && sudo chkconfig --level 35 ntpd on'
备注：这一步执行比较慢，执行完，时间也没同步成功，不知道为什么。但实际不影响数据库安装。

初始化前检查连通性
检查节点与节点之间文件读取；

cd /usr/local/greenplum-db/bin
gpcheckperf -f /home/gpadmin/conf/hostlist -r N -d /tmp

-------------------
--  NETPERF TEST
-------------------

====================
==  RESULT
====================
Netperf bisection bandwidth test
GP_Master -> GP_Segment_1 = 430.390000
GP_Segment_2 -> GP_Segment_3 = 429.400000
GP_Segment_1 -> GP_Master = 438.480000
GP_Segment_3 -> GP_Segment_2 = 434.780000

Summary:
sum = 1725.05 MB/sec
min = 429.40 MB/sec
max = 434.78 MB/sec
avg = 431.26 MB/sec
median = 430.48 MB/sec
出现以上内容证明各个节点已经可以连通



执行初始化
初始化 Greenplum 配置文件模板都在/usr/local/greenplum-db/docs/cli_help/gpconfigs目录下,gpinitsystem_config是初始化 Greenplum 的模板，此模板中 Mirror Segment的配置都被注释；创建一个副本，对其以下配置进行修改:
cd /usr/local/greenplum-db/docs/cli_help/gpconfigs
cp gpinitsystem_config initgp_config
vim initgp_config  

#以下为文本要修改的属性字段配置      
#资源目录为在4.1章节创建的资源目录，配置几次资源目录就是每个子节点有几个实例（推荐4-8个，这里配置了6个，primary与mirror文件夹个数对应）
declare -a DATA_DIRECTORY=(/opt/greenplum/data/primary /opt/greenplum/data/primary /opt/greenplum/data/primary /opt/greenplum/data2/primary /opt/greenplum/data2/primary /opt/greenplum/data2/primary)
declare -a MIRROR_DATA_DIRECTORY=(/opt/greenplum/data/mirror /opt/greenplum/data/mirror /opt/greenplum/data/mirror /opt/greenplum/data2/mirror /opt/greenplum/data2/mirror /opt/greenplum/data2/mirror)

ARRAY_NAME=”MAD_APES”                                        
MASTER_HOSTNAME=GP_Master                                   
MASTER_DIRECTORY=/opt/greenplum/data/master                 
MASTER_DATA_DIRECTORY=/opt/greenplum/data/master/gpseg-1    
DATABASE_NAME=MAD_APES                                       
MACHINE_LIST_FILE=/home/gpadmin/conf/seg_hosts             
---------------------

执行初始化；

gpinitsystem -c initgp_config -S

若初始化失败，需要删除/opt下的数据资源目录重新初始化；
若初始化成功，那恭喜你已经安装成功了。
```
# 停止和启动集群
gpstop -M fast
gpstart -a
